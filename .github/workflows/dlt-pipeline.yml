name: Run DLT Pipeline

on:
  workflow_dispatch: null
  schedule:
    - cron: "0 12 * * *"  # runs daily at 12:00 UTC

env:
  SOURCES__CREDENTIALS__AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  SOURCES__CREDENTIALS__AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  DESTINATION__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  DESTINATION__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  SOURCES__READERS__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  SOURCES__READERS__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  DESTINATION__FILESYSTEM__BUCKET_URL: ${{ secrets.DESTINATION_FILESYSTEM__BUCKET_URL }}
  SOURCES__BUCKET_URL: ${{ secrets.SOURCES__S3_TO_S3_NORMALIZATION_PIPELINE__FILESYSTEM__BUCKET_URL }}
  NORMALIZE__LOADER_FILE_FORMAT: parquet

jobs:
  run-dlt:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r dlt_normalization/requirements_dlt.txt

      - name: Run DLT Pipeline
        run: python dlt_normalization/s3_to_redshift_normalization_pipeline.py
